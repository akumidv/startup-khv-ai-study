{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sources\n",
    "* Yolo  https://proglib.io/p/raspoznavanie-obektov-s-pomoshchyu-yolo-v3-na-tensorflow-2-0-2020-11-08\n",
    "* Coco dataset https://cocodataset.org/#home\n",
    "* https://habr.com/ru/post/460869/\n",
    "\n",
    "Download yolo weights from `https://pjreddie.com/media/files/yolov3.weights` to `./data`\n",
    "\n",
    "condo install opencv tensorflow absl-py numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from absl import logging\n",
    "from itertools import repeat\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPool2D, UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow ver 2.3.0\n",
      "CV2 ver 4.0.1\n"
     ]
    }
   ],
   "source": [
    "print('Tensorflow ver', tf.__version__)\n",
    "print('CV2 ver', cv2.__version__)\n",
    "assert(tf.__version__.split('.')[0] >= '2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "yolo_iou_threshold   = 0.6 # порог пересечения относительно объединения (iou)\n",
    "yolo_score_threshold = 0.6\n",
    "\n",
    "weightsyolov3 = 'data/yolov3.weights' # путь к файлу весов\n",
    "weights= 'checkpoints/yolov3.tf' # путь к файлу checkpoint'ов\n",
    "size= 416             # приводим изображения к этому размеру\n",
    "checkpoints = 'checkpoints/yolov3.tf'\n",
    "num_classes = 80      # количество классов в модели\n",
    "\n",
    "# Список слоев в YOLOv3 FCN — Fully Convolutional Network\n",
    "YOLO_V3_LAYERS = [\n",
    "  'yolo_darknet',\n",
    "  'yolo_conv_0',\n",
    "  'yolo_output_0',\n",
    "  'yolo_conv_1',\n",
    "  'yolo_output_1',\n",
    "  'yolo_conv_2',\n",
    "  'yolo_output_2',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "'''\n",
    "Очень трудно загрузить веса с помощью чисто функционального API, поскольку порядок слоев в Darknet и tf.keras различаются. Здесь лучшее решение – создание подмоделей в keras. Для сохранения подмоделей рекомендуется использовать Checkpoint'ы Tensorflow, поскольку они официально поддерживаются Tensorflow.\n",
    "Функция для загрузки весов из оригинальной тренированной модели YOLO в Darknet:\n",
    "'''\n",
    "def load_darknet_weights(model, weights_file):\n",
    "  wf = open(weights_file, 'rb')\n",
    "  major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "  layers = YOLO_V3_LAYERS\n",
    "\n",
    "  for layer_name in layers:\n",
    "    sub_model = model.get_layer(layer_name)\n",
    "    for i, layer in enumerate(sub_model.layers):\n",
    "      if not layer.name.startswith('conv2d'):\n",
    "        continue\n",
    "      batch_norm = None\n",
    "      if i + 1 < len(sub_model.layers) and \\\n",
    "            sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "        batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "      logging.info(\"{}/{} {}\".format(\n",
    "        sub_model.name, layer.name, 'bn' if batch_norm else 'bias'))\n",
    "\n",
    "      filters = layer.filters\n",
    "      size = layer.kernel_size[0]\n",
    "      in_dim = layer.input_shape[-1]\n",
    "\n",
    "      if batch_norm is None:\n",
    "        conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "      else:\n",
    "        bn_weights = np.fromfile(\n",
    "          wf, dtype=np.float32, count=4 * filters)\n",
    "\n",
    "        bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "      conv_shape = (filters, in_dim, size, size)\n",
    "      conv_weights = np.fromfile(\n",
    "        wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "\n",
    "      conv_weights = conv_weights.reshape(\n",
    "        conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "      if batch_norm is None:\n",
    "        layer.set_weights([conv_weights, conv_bias])\n",
    "      else:\n",
    "        layer.set_weights([conv_weights])\n",
    "        batch_norm.set_weights(bn_weights)\n",
    "\n",
    "  assert len(wf.read()) == 0, 'не удалось прочитать все данные'\n",
    "  wf.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Функция для расчета пересечения относительно объединения\n",
    "def interval_overlap(interval_1, interval_2):\n",
    "  x1, x2 = interval_1\n",
    "  x3, x4 = interval_2\n",
    "  if x3 < x1:\n",
    "    return 0 if x4 < x1 else (min(x2,x4) - x1)\n",
    "  else:\n",
    "    return 0 if x2 < x3 else (min(x2,x4) - x3)\n",
    "\n",
    "def intersectionOverUnion(box1, box2):\n",
    "  intersect_w = interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "  intersect_h = interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "  intersect_area = intersect_w * intersect_h\n",
    "\n",
    "  w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "  w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Функция для отрисовки содержащей рамки, имени класса и вероятности\n",
    "def draw_outputs(img, outputs, class_names):\n",
    "  boxes, score, classes, nums = outputs\n",
    "  boxes, score, classes, nums = boxes[0], score[0], classes[0], nums[0]\n",
    "  wh = np.flip(img.shape[0:2])\n",
    "  for i in range(nums):\n",
    "    x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "    x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "    img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "      class_names[int(classes[i])], score[i]),\n",
    "      x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "  return img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Используем пакетную нормализацию (batch normalization), чтобы нормализовать результаты для ускорения тренировки. К сожалению, tf.keras.layers.BatchNormalization работает не очень хорошо для transfer learning, поэтому здесь предлагается другое решение этой проблемы.\n",
    "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
    "  def call(self, x, training=False):\n",
    "    if training is None: training = tf.constant(False)\n",
    "    training = tf.logical_and(training, self.trainable)\n",
    "    return super().call(x, training)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# сеть YOLOv3\n",
    "def DarknetConv(x, filters, size, strides=1, batch_norm=True):\n",
    "  if strides == 1:\n",
    "    padding = 'same'\n",
    "  else:\n",
    "    x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "    padding = 'valid'\n",
    "  x = Conv2D(filters=filters, kernel_size=size,\n",
    "          strides=strides, padding=padding,\n",
    "          use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "  if batch_norm:\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "  return x\n",
    "\n",
    "def DarknetResidual(x, filters):\n",
    "  previous  = x\n",
    "  x = DarknetConv(x, filters // 2, 1)\n",
    "  x = DarknetConv(x, filters, 3)\n",
    "  x = Add()([previous , x])\n",
    "  return x\n",
    "\n",
    "\n",
    "def DarknetBlock(x, filters, blocks):\n",
    "  x = DarknetConv(x, filters, 3, strides=2)\n",
    "  for _ in repeat(None, blocks):\n",
    "    x = DarknetResidual(x, filters)\n",
    "  return x\n",
    "\n",
    "\n",
    "def Darknet(name=None):\n",
    "  x = inputs = Input([None, None, 3])\n",
    "  x = DarknetConv(x, 32, 3)\n",
    "  x = DarknetBlock(x, 64, 1)\n",
    "  x = DarknetBlock(x, 128, 2)\n",
    "  x = x_36 = DarknetBlock(x, 256, 8)\n",
    "  x = x_61 = DarknetBlock(x, 512, 8)\n",
    "  x = DarknetBlock(x, 1024, 4)\n",
    "  return tf.keras.Model(inputs, (x_36, x_61, x), name=name)\n",
    "\n",
    "def YoloConv(filters, name=None):\n",
    "  def yolo_conv(x_in):\n",
    "    if isinstance(x_in, tuple):\n",
    "      inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "      x, x_skip = inputs\n",
    "\n",
    "      x = DarknetConv(x, filters, 1)\n",
    "      x = UpSampling2D(2)(x)\n",
    "      x = Concatenate()([x, x_skip])\n",
    "    else:\n",
    "      x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "    x = DarknetConv(x, filters, 1)\n",
    "    x = DarknetConv(x, filters * 2, 3)\n",
    "    x = DarknetConv(x, filters, 1)\n",
    "    x = DarknetConv(x, filters * 2, 3)\n",
    "    x = DarknetConv(x, filters, 1)\n",
    "    return Model(inputs, x, name=name)(x_in)\n",
    "  return yolo_conv\n",
    "\n",
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "  def yolo_output(x_in):\n",
    "    x = inputs = Input(x_in.shape[1:])\n",
    "    x = DarknetConv(x, filters * 2, 3)\n",
    "    x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "    x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\n",
    "                                        anchors, classes + 5)))(x)\n",
    "    return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "  return yolo_output\n",
    "\n",
    "def yolo_boxes(pred, anchors, classes):\n",
    "  grid_size = tf.shape(pred)[1]\n",
    "  box_xy, box_wh, score, class_probs = tf.split(pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "  box_xy = tf.sigmoid(box_xy)\n",
    "  score = tf.sigmoid(score)\n",
    "  class_probs = tf.sigmoid(class_probs)\n",
    "  pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "\n",
    "  grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "  grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "\n",
    "  box_xy = (box_xy + tf.cast(grid, tf.float32)) /  tf.cast(grid_size, tf.float32)\n",
    "  box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "  box_x1y1 = box_xy - box_wh / 2\n",
    "  box_x2y2 = box_xy + box_wh / 2\n",
    "  bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "  return bbox, score, class_probs, pred_box"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Подавление не-максимумов\n",
    "def nonMaximumSuppression(outputs, anchors, masks, classes):\n",
    "  boxes, conf, out_type = [], [], []\n",
    "\n",
    "  for output in outputs:\n",
    "    boxes.append(tf.reshape(output[0], (tf.shape(output[0])[0], -1, tf.shape(output[0])[-1])))\n",
    "    conf.append(tf.reshape(output[1], (tf.shape(output[1])[0], -1, tf.shape(output[1])[-1])))\n",
    "    out_type.append(tf.reshape(output[2], (tf.shape(output[2])[0], -1, tf.shape(output[2])[-1])))\n",
    "\n",
    "  bbox = tf.concat(boxes, axis=1)\n",
    "  confidence = tf.concat(conf, axis=1)\n",
    "  class_probs = tf.concat(out_type, axis=1)\n",
    "\n",
    "  scores = confidence * class_probs\n",
    "\n",
    "  boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "    boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "    scores=tf.reshape(\n",
    "        scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "    max_output_size_per_class=100,\n",
    "    max_total_size=100,\n",
    "    iou_threshold=yolo_iou_threshold,\n",
    "    score_threshold=yolo_score_threshold\n",
    "  )\n",
    "\n",
    "  return boxes, scores, classes, valid_detections"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yolo_anchors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-31-ee35b5f7f5f7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Основная функция, создающая всю модель:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m def YoloV3(size=None, channels=3, anchors=yolo_anchors,\n\u001B[0m\u001B[0;32m      3\u001B[0m           masks=yolo_anchor_masks, classes=80, training=False):\n\u001B[0;32m      4\u001B[0m   \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchannels\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'yolo_anchors' is not defined"
     ]
    }
   ],
   "source": [
    "# Основная функция, создающая всю модель:\n",
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors,\n",
    "          masks=yolo_anchor_masks, classes=80, training=False):\n",
    "  x = inputs = Input([size, size, channels])\n",
    "\n",
    "  x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "  x = YoloConv(512, name='yolo_conv_0')(x)\n",
    "  output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "\n",
    "  x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "  output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "  x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "  output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "\n",
    "  if training:\n",
    "    return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "\n",
    "  boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                  name='yolo_boxes_0')(output_0)\n",
    "  boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                  name='yolo_boxes_1')(output_1)\n",
    "  boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                  name='yolo_boxes_2')(output_2)\n",
    "\n",
    "  outputs = Lambda(lambda x: nonMaximumSuppression(x, anchors, masks, classes),\n",
    "                  name='nonMaximumSuppression')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "\n",
    "  return Model(inputs, outputs, name='yolov3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Функция потерь с декоратором\n",
    "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        # 1. transform all pred outputs\n",
    "        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(\n",
    "            y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "\n",
    "        # 2. transform all true outputs\n",
    "        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n",
    "        true_box, true_obj, true_class_idx = tf.split(\n",
    "            y_true, (4, 1, 1), axis=-1)\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
    "\n",
    "        # give higher weights to small boxes\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
    "            tf.cast(grid, tf.float32)\n",
    "        true_wh = tf.math.log(true_wh / anchors)\n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh),\n",
    "                           tf.zeros_like(true_wh), true_wh)\n",
    "\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        # ignore false positive when iou is over threshold\n",
    "        true_box_flat = tf.boolean_mask(true_box, tf.cast(obj_mask, tf.bool))\n",
    "        best_iou = tf.reduce_max(broadcast_iou(\n",
    "            pred_box, true_box_flat), axis=-1)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        obj_loss = obj_mask * obj_loss + \\\n",
    "            (1 - obj_mask) * ignore_mask * obj_loss\n",
    "        # TODO: use binary_crossentropy instead\n",
    "        class_loss = obj_mask * sparse_categorical_crossentropy(\n",
    "            true_class_idx, pred_class)\n",
    "\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    return yolo_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#функция трансформирует целевые выводы к кортежу\n",
    "@tf.function\n",
    "def transform_targets_for_output(y_true, grid_size, anchor_idxs, classes):\n",
    "\n",
    "  N = tf.shape(y_true)[0]\n",
    "\n",
    "  y_true_out = tf.zeros(\n",
    "      (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n",
    "\n",
    "  anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n",
    "\n",
    "  indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "  updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "  idx = 0\n",
    "  for i in tf.range(N):\n",
    "    for j in tf.range(tf.shape(y_true)[1]):\n",
    "      if tf.equal(y_true[i][j][2], 0):\n",
    "        continue\n",
    "      anchor_eq = tf.equal(\n",
    "        anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))\n",
    "\n",
    "      if tf.reduce_any(anchor_eq):\n",
    "        box = y_true[i][j][0:4]\n",
    "        box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\n",
    "\n",
    "        anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n",
    "        grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)\n",
    "\n",
    "        indexes = indexes.write(\n",
    "            idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n",
    "        updates = updates.write(\n",
    "          idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])\n",
    "        idx += 1\n",
    "\n",
    "  return tf.tensor_scatter_nd_update(\n",
    "    y_true_out, indexes.stack(), updates.stack())\n",
    "\n",
    "\n",
    "def transform_targets(y_train, anchors, anchor_masks, classes):\n",
    "  outputs = []\n",
    "  grid_size = 13\n",
    "\n",
    "  anchors = tf.cast(anchors, tf.float32)\n",
    "  anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "  box_wh = y_train[..., 2:4] - y_train[..., 0:2]\n",
    "  box_wh = tf.tile(tf.expand_dims(box_wh, -2),\n",
    "                    (1, 1, tf.shape(anchors)[0], 1))\n",
    "  box_area = box_wh[..., 0] * box_wh[..., 1]\n",
    "  intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * \\\n",
    "    tf.minimum(box_wh[..., 1], anchors[..., 1])\n",
    "  iou = intersection / (box_area + anchor_area - intersection)\n",
    "  anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n",
    "  anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n",
    "\n",
    "  y_train = tf.concat([y_train, anchor_idx], axis=-1)\n",
    "\n",
    "  for anchor_idxs in anchor_masks:\n",
    "    outputs.append(transform_targets_for_output(\n",
    "      y_train, grid_size, anchor_idxs, classes))\n",
    "    grid_size *= 2\n",
    "\n",
    "  return tuple(outputs) # [x, y, w, h, obj, class]\n",
    "\n",
    "\n",
    "def preprocess_image(x_train, size):\n",
    "  return (tf.image.resize(x_train, (size, size))) / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YoloV3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-34-28b38603e361>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0myolo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mYoloV3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclasses\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mload_darknet_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0myolo\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweightsyolov3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0myolo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcheckpoints\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'YoloV3' is not defined"
     ]
    }
   ],
   "source": [
    "yolo = YoloV3(classes=num_classes)\n",
    "\n",
    "load_darknet_weights(yolo, weightsyolov3)\n",
    "\n",
    "yolo.save_weights(checkpoints)\n",
    "\n",
    "class_names =  [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "  \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "  \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "  \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "  \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "  \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
    "  \"banana\",\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\",\n",
    "  \"cake\",\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\",\n",
    "  \"mouse\",\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "  \"refrigerator\",\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name = 'detect.jpg'\n",
    "img = tf.image.decode_image(open(name, 'rb').read(), channels=3)\n",
    "img = tf.expand_dims(img, 0)\n",
    "img = preprocess_image(img, size)\n",
    "\n",
    "boxes, scores, classes, nums = yolo(img) #eager mode\n",
    "\n",
    "img = cv2.imread(name)\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
    "cv2.imwrite('output.jpg', img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = tf.expand_dims(frame, 0)\n",
    "    img = preprocess_image(img, size)\n",
    "    boxes, scores, classes, nums = yolo(img) #eager mode\n",
    "    img = draw_outputs(frame, (boxes, scores, classes, nums), class_names)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}